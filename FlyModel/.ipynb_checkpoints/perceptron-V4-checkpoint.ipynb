{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data, label, lr, n_class, shift):\n",
    "    from collections import Counter\n",
    "    weights = np.zeros([n_class,n_kc])#*10.0\n",
    "    kcs = np.array([get_KC(np.array(data.iloc[i,:]),R,thresh) for i in range(data.shape[0])])\n",
    "    distinct_label = np.sort(list(Counter(label).keys()))\n",
    "    if len(distinct_label) != n_class:\n",
    "        raise ValueError('Number of classes to be trained does not match!!!')\n",
    "    for i in range(n_class):\n",
    "        this_class = kcs[np.array(label==distinct_label[i])]\n",
    "        for j in range(len(this_class)):\n",
    "            out = np.matmul(weights, this_class[j])\n",
    "            predict = np.random.choice(np.flatnonzero(out == out.max()))\n",
    "            if not (distinct_label[i]-shift == predict):\n",
    "                weights[distinct_label[i]-shift] += lr*this_class[j]\n",
    "                #weights[predict] -= lr*this_class[j]\n",
    "            else:\n",
    "                weights[predict] += lr*this_class[j]\n",
    "            #weights[weights<0] = 0\n",
    "            weights[weights>1] = 1\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('./processed_data/mnist_kmnist_train.csv',header=None)\n",
    "mnist_train_label = pd.read_csv('./processed_data/mnist_kmnist_train_label.csv',header=None)\n",
    "mnist_train_label = np.array([x[0] for x in np.array(mnist_train_label)])\n",
    "fmnist_train = pd.read_csv('./processed_data/fmnist_kmnist_train.csv',header=None)\n",
    "fmnist_train_label = pd.read_csv('./processed_data/fmnist_kmnist_train_label.csv',header=None)\n",
    "fmnist_train_label = np.array([x[0] for x in np.array(fmnist_train_label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = pd.read_csv('./processed_data/mnist_kmnist_test.csv',header=None)\n",
    "mnist_test_label = pd.read_csv('./processed_data/mnist_kmnist_test_label.csv',header=None)\n",
    "mnist_test_label = np.array([x[0] for x in np.array(mnist_test_label)])\n",
    "fmnist_test = pd.read_csv('./processed_data/fmnist_kmnist_test.csv',header=None)\n",
    "fmnist_test_label = pd.read_csv('./processed_data/fmnist_kmnist_test_label.csv',header=None)\n",
    "fmnist_test_label = np.array([x[0] for x in np.array(fmnist_test_label)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([mnist_train, fmnist_train],axis=0,ignore_index=True)\n",
    "test_data = pd.concat([mnist_test, fmnist_test],axis=0,ignore_index=True)\n",
    "train_label = np.concatenate([mnist_train_label, fmnist_train_label+10])\n",
    "test_label = np.concatenate([mnist_test_label, fmnist_test_label+10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import minmax_scale\n",
    "train_data = pd.DataFrame(minmax_scale(train_data,axis=1))\n",
    "test_data = pd.DataFrame(minmax_scale(test_data,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_transformation_matrix(n_kc,n_orn,n_response):\n",
    "    R = np.zeros((n_kc, n_orn))\n",
    "    for i in range(n_kc):\n",
    "        random.seed(i)\n",
    "        R[i,random.sample(list(range(n_orn)), n_response)] = 1\n",
    "    return R\n",
    "\n",
    "def get_KC(p,R,thresh):\n",
    "    '''\n",
    "    odor: a vector of ORN responses for a given odor\n",
    "    w: inhibitory synaptic strength from LN to PN\n",
    "    R: random linear transformation matrix from PN to KC\n",
    "    thresh: rectlinear threshold for KC activation\n",
    "    '''\n",
    "    KC = np.matmul(R,p)\n",
    "    KC[KC<=thresh] = 0\n",
    "    threshold = np.quantile(KC,0.95)\n",
    "    KC[KC<threshold] = 0\n",
    "    KC = KC/np.max(KC)\n",
    "    return KC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, labels, split):\n",
    "    from collections import Counter\n",
    "    distinct_labels = list(Counter(labels).keys())\n",
    "    n_labels = len(distinct_labels)\n",
    "    n_split = int(n_labels/split)\n",
    "    trans = data.T\n",
    "    trans.columns = labels\n",
    "    datasets = {}\n",
    "    datalabels = {}\n",
    "    for i in range(n_split):\n",
    "        cond1 = trans.columns.values >= i*split\n",
    "        cond2 = trans.columns.values < (i+1)*split\n",
    "        out = trans.iloc[:,cond1&cond2]\n",
    "        out_label = out.columns.values\n",
    "        datasets[i] = out.T\n",
    "        datalabels[i] = out_label\n",
    "    return (datasets, datalabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(weights, data, label):\n",
    "    kcs = np.array([get_KC(np.array(data.iloc[i,:]),R,thresh) for i in range(data.shape[0])])\n",
    "    result = np.matmul(weights, kcs.T)\n",
    "    pred = np.argmax(result, axis=0)\n",
    "    return np.sum(pred==label)/len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_kc = 3200\n",
    "n_orn = 84\n",
    "n_response = 10\n",
    "R = generate_transformation_matrix(n_kc,n_orn,n_response)\n",
    "thresh = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datasets, train_labels = split_data(train_data, train_label, 2)\n",
    "test_datasets, test_labels = split_data(test_data, test_label, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_task = 10\n",
    "lrs = [0.1, 0.01, 0.001, 0.0001]\n",
    "for lr in lrs:\n",
    "    accuracy = np.zeros([n_task, n_task])\n",
    "    trained_weights = {}\n",
    "    for i in range(n_task):\n",
    "        trained_weights[i] = train(train_datasets[i], train_labels[i], lr, 2, i*2)\n",
    "\n",
    "        weights_to_test = np.concatenate([trained_weights[j] for j in range(i+1)])\n",
    "\n",
    "        for j in range(i+1):\n",
    "            accuracy[i,j] = accu(weights_to_test,test_datasets[j],test_labels[j])\n",
    "\n",
    "    accuracy = pd.DataFrame(accuracy)\n",
    "    accuracy.to_csv('./accuracy/Sparse-coding_v4_lr'+str(lr)+'.csv',index=False,header=False)\n",
    "    \n",
    "    print('learning rate '+str(lr)+' done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
